#!/usr/bin/env python

import scraperwiki
import requests
import lxml.html


html = requests.get("http://abilitazione.miur.it/public/pubblicarisultati.php").content

# retrieve list of sectors from home page

def get_sectors():
    '''Retrieve list of sectors.'''

    dom = lxml.html.fromstring(html)
    for sec in dom.cssselect("#frmCercaId select option"):
            sector = {'code': sec.get('value'), 'name': sec.text_content()}
            if sector['code'] not in ['1', '2', '']:
                scraperwiki.sql.save(['code', 'name'], sector, table_name="sectors")

# for each list, retrieve single candidates (id, name, indicators URL, CV PDF, assessment PDF, yes/no)

def get_candidates(sector):
    '''Retrieve list of candidates for a sector.'''
    
    payload = {'settore': sector, 'fascia': rank}
    html = requests.post("http://abilitazione.miur.it/public/pubblicarisultati.php", params=payload).content
    
    dom = lxml.html.fromstring(html)
    for c in dom.cssselect("#elencodomande tbody tr"):
        data={
            'cognome': c.cssselect('td')[0].text_content()
            }
        print(data)

get_candidates('01/A2', '1')

# Saving data:
# unique_keys = [ 'id' ]
# data = { 'id':12, 'name':'violet', 'age':7 }
# scraperwiki.sql.save(unique_keys, data)
