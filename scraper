#!/usr/bin/env python
# -*- coding: utf-8 -*-

import scraperwiki
import requests
import lxml.html


html = requests.get("http://abilitazione.miur.it/public/pubblicarisultati.php").content

# retrieve list of sectors from home page

def get_sectors():
    '''Retrieve list of sectors.'''

    dom = lxml.html.fromstring(html)
    for sec in dom.cssselect("#frmCercaId select option"):
            sector = {'code': sec.get('value'), 'name': sec.text_content()}
            if sector['code'] not in ['1', '2', '']:
                scraperwiki.sql.save(['code', 'name'], sector, table_name="sectors")

# for each list, retrieve single candidates (id, name, indicators URL, CV PDF, assessment PDF, yes/no)

def get_candidates(sector, rank):
    '''Retrieve list of candidates for a sector.'''
    
    payload = {'settore': sector, 'fascia': rank}
    html = requests.post("http://abilitazione.miur.it/public/pubblicarisultati.php", params=payload).content
    store = [] # fill memory, not I/O
    
    dom = lxml.html.fromstring(html)
    for c in dom.cssselect("#elencodomande tbody tr"):
        data={
            'cognome': c.cssselect('td')[0].text_content(),
            'nome': c.cssselect('td')[1].text_content(),
            'id': int(c.cssselect('td.CV a')[0].get('href').split('/')[-3]),
            'ppv': int(c.cssselect('td.PPV')[0].text_content().strip()),
            'accepted': True if c.cssselect('td')[-1].text_content().strip() == 'Si' else False, # Correct spelling is 'SÃ¬', FFS
            'sector': sector,
            'rank': rank,
            }
        store.append(data)
    scraperwiki.sql.save(['id'], store, table_name='candidates')

def main():
    for sector in scraperwiki.sql.select("* FROM sectors"):
        #get_candidates(sector['code'], '1')
        #get_candidates(sector['code'], '2')
        print('%s DONE!')

main()
